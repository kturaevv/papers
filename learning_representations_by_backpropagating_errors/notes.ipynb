{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning representations by back-propagating errors\n",
    "\n",
    "---\n",
    "**Quick summary:** *paper that introduced and popularized the concept of backpropagation for Neural Networks*\n",
    "\n",
    "> The task is specified by giving the desired state vector of the output units for each state vector of the input units\n",
    "\n",
    "Quite convoluted way of saying that to make a network train we need to provide it the intput data with corresponding output we hope to achieve, i.e. a supervised learning. In other words, to map inputs to the outputs with the data.\n",
    "\n",
    "> ... state of the units in each layer are determined by applying equations (1) and (2) ...\n",
    "\n",
    "Description of how Neural Networks work, i.e. every output of a layer should correspond to every input node of next layer. And layers are pieced together by a linking linear function with non-linearity.\n",
    "\n",
    "A Unit consist of 2 values which is a **weight** and a **bias**. In a modern terminology this is reffered to as a *Neuron*\n",
    "\n",
    "> The total input, $x_{j}$ to unit j is a linear function of the outputs,\n",
    "> $y_{i}$ of the units that are connected to j and of the weights, $w_{ji}$\n",
    "> on these connections $$ x_{j} = \\sum_{i}y_{i}w_{ji} $$\n",
    "\n",
    "... the states of the \"units\", aka Neurons, are evaluated by the linear relation of inputs, which means that an output of neuron $x_{j}$, is a sum of weights of every input to every weight of the Neuron:\n",
    "\n",
    "```python\n",
    "    def __call__(self, y: \"Units\") -> \"Units\":\n",
    "        x_j = sum(y_i * w_ji for y_i, w_ji in zip(y.w, self.w))\n",
    "        return x_j\n",
    "```\n",
    "\n",
    "> A unit has a real-valued output, $y_{j}$ which is a non-linear function of its total input $$ y_{j} = {1 \\over 1 + e^{-x_{j}} }$$\n",
    "\n",
    "This is the non-linearity that makes the network learn stuff, which is commonly reffered to as *activation function*. The one mentioned in the paper is *Sigmoid activation function*.\n",
    "\n",
    "```python\n",
    "    def sigmoid(self) -> \"Scalar\":\n",
    "        return 1 / (1 + math.exp(-self.w))\n",
    "\n",
    "    def __call__(self, y: \"Units\") -> \"Units\":\n",
    "        x_j = sum(y_i * w_ji for y_i, w_ji in zip(y.w, self.w))\n",
    "        out = x_j.sigmoid() # add non-linearity\n",
    "        return out\n",
    "```\n",
    "\n",
    "Based on above mentioned ideas it is enough to \"build\" the basic implementation for a simplest, non-optimized neural network, featuring:\n",
    "- Scalar: the most basic building block of a Neural network\n",
    "- Units: aka Neurons\n",
    "- State Vector: aka Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Scalar(w=0.6450641037423873)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "class Scalar:\n",
    "    \n",
    "    def __init__(self, data = None) -> None:\n",
    "        self.data: float = data if data is not None else random.uniform(-1, 1)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"Scalar(w={self.data})\"\n",
    "\n",
    "    def __add__(self, other: \"Scalar\") -> \"Scalar\":\n",
    "        if not isinstance(other, Scalar):\n",
    "            other = Scalar(other)\n",
    "\n",
    "        out = self.data + other.data\n",
    "        return Scalar(out)\n",
    "\n",
    "    def __mul__(self, other: \"Scalar\") -> \"Scalar\":\n",
    "        if not isinstance(other, Scalar):\n",
    "            other = Scalar(other)\n",
    "\n",
    "        out = self.data * other.data\n",
    "        return Scalar(out)\n",
    "\n",
    "    def __pow__(self, power: int):\n",
    "        if isinstance(power, Scalar):\n",
    "            power = power.data\n",
    "        out = self.data ** power\n",
    "        return Scalar(out)\n",
    "    \n",
    "    \"\"\" Handle other use cases using base operations. \"\"\"\n",
    "\n",
    "    def __neg__(self) -> \"Scalar\":  # -self\n",
    "        return self * -1\n",
    "\n",
    "    def __radd__(self, other: \"Scalar\") -> \"Scalar\":  # other + self\n",
    "        return self + other\n",
    "\n",
    "    def __sub__(self, other: \"Scalar\") -> \"Scalar\":  # self - other\n",
    "        return self + (-other)\n",
    "\n",
    "    def __rsub__(self, other: \"Scalar\") -> \"Scalar\":  # other - self\n",
    "        return other + (-self)\n",
    "\n",
    "    def __rmul__(self, other: \"Scalar\") -> \"Scalar\":  # other * self\n",
    "        return self * other\n",
    "\n",
    "    def __truediv__(self, other: \"Scalar\") -> \"Scalar\":  # self / other\n",
    "        return self * other**-1\n",
    "\n",
    "    def __rtruediv__(self, other: \"Scalar\") -> \"Scalar\":  # other / self\n",
    "        return other * self**-1\n",
    "\n",
    "    def sigmoid(self) -> \"Scalar\":\n",
    "        return Scalar(1 / (1 + math.exp(-self.data)))\n",
    "\n",
    "\n",
    "class Units: # aka a single Neuron\n",
    "    \n",
    "    def __init__(self, n_in: int) -> None:\n",
    "        self.w: list[Scalar] = [Scalar(random.uniform(-1, 1)) for _ in range(n_in)]\n",
    "        self.bias: float = Scalar(1.0)\n",
    "\n",
    "    def __call__(self, y: list[\"Scalar\"]) -> \"Units\":\n",
    "        if len(y) != len(self.w): \n",
    "            raise BaseException(\"Incorrect Dimensions\")\n",
    "\n",
    "        x_j: Scalar = sum((y_i * w_ji for y_i, w_ji in zip(y, self.w)), self.bias)\n",
    "        out = x_j.sigmoid()\n",
    "        return out\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        doc: str = \"Unit[\\n\"\n",
    "        for x_i in self.w:\n",
    "            doc += \"\\t\" + x_i.__str__() + \"\\n\"\n",
    "        doc += \"]\"\n",
    "        return doc\n",
    "\n",
    "    def parameters(self):\n",
    "        return self.w + [self.bias]\n",
    "\n",
    "\n",
    "class StateVector: # aka Tensor\n",
    "    \n",
    "    def __init__(self, n_in: int, n_out: int) -> None:\n",
    "        self.n_in: int = n_in\n",
    "        self.n_out: int = n_out\n",
    "        self.units: list[Units] = [Units(n_in) for _ in range(n_out)]\n",
    "\n",
    "    def __call__(self, y: list[\"Scalar\"]) -> \"StateVector\":\n",
    "        out: list[Units] = [unit(y) for unit in self.units]\n",
    "        return out\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        doc: str = f\"StateVector[{self.n_in}, {self.n_out}][\\n\"\n",
    "        for j in self.units:\n",
    "            doc += \"  \" + j.__str__() + \"\\n\"\n",
    "        doc += \"]\"\n",
    "        return doc\n",
    "\n",
    "    def parameters(self):\n",
    "        return [weights for unit in self.units for weights in unit.parameters()] \n",
    "    \n",
    "\n",
    "class NeuralNetwork: \n",
    "    def __init__(self, n_in, layers: list[StateVector]) -> None:\n",
    "        self.n_in = n_in\n",
    "        self.layers: list[StateVector] = layers\n",
    "\n",
    "    def __call__(self, x: list[\"Scalar\"]):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "    def parameters(self) -> list[Scalar]:\n",
    "        return [weights for layer in self.layers for weights in layer.parameters()] \n",
    "    \n",
    "mlp = NeuralNetwork(1, [\n",
    "    StateVector(1, 10),\n",
    "    StateVector(10, 10),\n",
    "    StateVector(10, 1)\n",
    "])\n",
    "mlp([1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The aim is to find a set of weights that ensure that for each\n",
    "> input vector the output vector produced by the network is the\n",
    "> same as (or sufficiently close to) the desired output vector. If\n",
    "> there is a fixed, finite set of input-output cases, the total error\n",
    "> inthe performance ofthe network with a particular set of weights\n",
    "> can be computed by comparing the actual and desired output\n",
    "> vectors for every case. The total error E, is defined as:\n",
    "> $$ \\dfrac{1}{2} \\sum_{c} \\sum_{j} (y_{j,c} - d_{j,c})^2 $$\n",
    "\n",
    "One of the most fundamental parats of the learning purpose - loss function. Nothing to add, the description is pretty self explanotory. \n",
    "In simple words the idea is to calculate the difference between the output of a network and a desired state.\n",
    "\n",
    "Let's say we want to approximate the following function of $sin$ between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAADvCAYAAAAgn9RXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABJaklEQVR4nO3deVxU9f7H8dfMAMMOKsiiuOGCC4obiIrLVaM0l8zrmlupLWaLmWW3orKy+pXVNXMrxVxyyy0zcy8XFENRFDUXXBEUlUV2Zs7vD3JuKCrgwGHg83w85vFwzpwz85mvA/Pme77f79EoiqIghBBCCKESrdoFCCGEEKJykzAihBBCCFVJGBFCCCGEqiSMCCGEEEJVEkaEEEIIoSoJI0IIIYRQlYQRIYQQQqhKwogQQgghVCVhRAghhBCqkjAiKp06deowatQotcuwGBqNhvfee0/tMkQFs3PnTjQaDTt37lS7FFEOSBgRFUZMTAwDBgygdu3a2NraUqNGDXr06MGMGTPULg343y/fwm6DBw9WtbaNGzeWu8Dx3nvvFWgjrVaLl5cXjz/+OPv27Svx83788cesXbvWfIWWQ8nJyYwbNw53d3ccHBzo2rUrBw8eVLusErl16xZhYWE8+uijVK1aFY1GQ3h4uNplCTOzUrsAIcxh7969dO3alVq1ajF27Fg8PT25ePEi+/bt4+uvv2bChAmmfU+ePIlWq14Of+mll2jbtm2BbXXq1FGnmL9t3LiRmTNnFhpIMjMzsbJS71fFrFmzcHR0xGg0cvHiRebNm0enTp2IjIwkICCg2M/38ccfM2DAAPr162f2WssDo9FIr169OHz4MK+//jpubm58++23dOnShaioKBo0aKB2icWSlJTEBx98QK1atWjRooX0pFRQEkZEhfDRRx/h4uLCgQMHcHV1LfDY1atXC9zX6/VlWNndQkJCGDBggKo1FIetra2qrz9gwADc3NxM9/v160ezZs1YuXJlicJIRbdq1Sr27t3LypUrTZ+zgQMH0rBhQ8LCwli6dKnKFRaPl5cXV65cwdPTkz///POuIC8qBjlNIyqEM2fO0LRp07uCCED16tUL3L9zzEh4eDgajYY9e/YwceJEU9f2E088wbVr1+56vl9//ZWQkBAcHBxwcnKiV69eHDt2zCzv417jWbp06UKXLl1M92+f8lmxYgUfffQRNWvWxNbWlm7dunH69Om7jt+/fz89e/akSpUqODg40Lx5c77++msARo0axcyZMwEKnBa5rbAxI4cOHeKxxx7D2dkZR0dHunXrdtepk+K2a1F5enoC3NVbk52dTVhYGPXr10ev1+Pj48PkyZPJzs4u8F7S09NZuHCh6X2OGjWKI0eOoNFoWL9+vWnfqKgoNBoNrVq1KvA6jz32GEFBQQW2FfUzceLECQYMGEDVqlWxtbWlTZs2BV4THr7dVq1ahYeHB/379zdtc3d3Z+DAgaxbt65AexRm3bp19OrVC29vb/R6Pb6+vkydOhWDwVBgvy5dutCsWTNiY2Pp2rUr9vb21KhRg88+++yu57x06RL9+vXDwcGB6tWr8+qrrz6wjtv0er3p/1xUXNIzIiqE2rVrExERwdGjR2nWrFmJnmPChAlUqVKFsLAwzp07x1dffcWLL77I8uXLTfssWrSIkSNHEhoayqeffkpGRgazZs2iY8eOHDp0qEinW9LS0khKSiqwrWrVqiU6dfTJJ5+g1WqZNGkSKSkpfPbZZwwbNoz9+/eb9tmyZQuPP/44Xl5evPzyy3h6enL8+HE2bNjAyy+/zLPPPkt8fDxbtmxh0aJFD3zNY8eOERISgrOzM5MnT8ba2po5c+bQpUsXfv/997u+qIvSrvdz48YNIP/0w+XLl5k6dSq2trYMHDjQtI/RaKRPnz7s3r2bcePG0bhxY2JiYvjyyy/566+/TGNEFi1axJgxYwgMDGTcuHEA+Pr60qxZM1xdXfnjjz/o06cPALt27UKr1XL48GFSU1NxdnbGaDSyd+9e07G3n7Mon4ljx47RoUMHatSowZtvvomDgwMrVqygX79+/PTTTzzxxBNmabdDhw7RqlWruz5PgYGBzJ07l7/++gt/f/97Hh8eHo6joyMTJ07E0dGR7du38+6775Kamsr//d//Fdj35s2bPProo/Tv35+BAweyatUq3njjDfz9/XnssceA/NN83bp148KFC7z00kt4e3uzaNEitm/fft/3ISoZRYgKYPPmzYpOp1N0Op0SHBysTJ48Wfntt9+UnJycu/atXbu2MnLkSNP9BQsWKIDSvXt3xWg0mra/+uqrik6nU5KTkxVFUZS0tDTF1dVVGTt2bIHnS0hIUFxcXO7afqcdO3YoQKG3uLi4Qmu7rXPnzkrnzp3veq7GjRsr2dnZpu1ff/21AigxMTGKoihKXl6eUrduXaV27drKzZs3CzznP9/r+PHjlXv9OgCUsLAw0/1+/fopNjY2ypkzZ0zb4uPjFScnJ6VTp06mbUVt13sJCwsrtK1cXV2VTZs2Fdh30aJFilarVXbt2lVg++zZsxVA2bNnj2mbg4NDoW3cq1cvJTAw0HS/f//+Sv/+/RWdTqf8+uuviqIoysGDBxVAWbdunaIoxftMdOvWTfH391eysrJM24xGo9K+fXulQYMGZms3BwcH5emnn75r+y+//KIAd7XdnTIyMu7a9uyzzyr29vYFau/cubMCKD/88INpW3Z2tuLp6ak8+eSTpm1fffWVAigrVqwwbUtPT1fq16+vAMqOHTvuW88/HThwQAGUBQsWFPkYYRnkNI2oEHr06EFERAR9+vTh8OHDfPbZZ4SGhlKjRo27usHvZdy4cQVOT4SEhGAwGDh//jyQ38OQnJzMkCFDSEpKMt10Oh1BQUHs2LGjSK/z7rvvsmXLlgK3knZDjx49GhsbmwI1A5w9exbI/ys5Li6OV1555a5TWP98r0VlMBjYvHkz/fr1o169eqbtXl5eDB06lN27d5OamlrgmAe164P89NNPbNmyhc2bN7NgwQIaNmzIk08+yd69e037rFy5ksaNG+Pn51fg/+Zf//oXQJH+b0JCQjh48CDp6ekA7N69m549exIQEMCuXbuA/N4SjUZDx44dgaJ/Jm7cuMH27dsZOHCgqWcsKSmJ69evExoayqlTp7h8+bJZ2i0zM7PQcVG3x/5kZmbe93g7OzvTv2/XGhISQkZGBidOnCiwr6OjI0899ZTpvo2NDYGBgabPH+QPjvby8iowTsre3r5A75IQcppGVBht27Zl9erV5OTkcPjwYdasWcOXX37JgAEDiI6OpkmTJvc9vlatWgXuV6lSBcjvigY4deoUgOkL7k7Ozs5FqtPf35/u3bsXad8HeVDNZ86cASjxqas7Xbt2jYyMDBo1anTXY40bNzbNeGnatGmRa3yQTp06FRjAOmDAABo0aMCECROIiooC8v9vjh8/jru7e6HPcecg5sKEhISQl5dHREQEPj4+XL16lZCQEI4dO1YgjDRp0oSqVauaXhce/Jk4ffo0iqLwzjvv8M4779yzxho1apjul7Td7OzsCh2PkZWVZXr8fo4dO8bbb7/N9u3b7wqWKSkpBe7XrFnzrlBbpUoVjhw5Yrp//vx56tevf9d+hX2GROUlYURUODY2NrRt25a2bdvSsGFDRo8ezcqVKwkLC7vvcTqdrtDtiqIA+eMSIH+MQGE9GeaY/nqv3gqDwVBofQ+quTwwd42Ojo4EBQWxbt060tPTcXBwwGg04u/vz/Tp0ws9xsfH54HP26ZNG2xtbfnjjz+oVasW1atXp2HDhoSEhPDtt9+SnZ3Nrl27CoztKOpn4vZ+kyZNIjQ0tNDXr1+/foH7JW2327NP7nR7m7e39z2PTU5OpnPnzjg7O/PBBx/g6+uLra0tBw8e5I033jC9j4etUYg7SRgRFVqbNm0ACv3lXFy+vr5A/uwcc/Vs3KlKlSokJyfftf38+fMFTosU1e2ajx49et+ai3rKxt3dHXt7e06ePHnXYydOnECr1Rbpi/9h5eXlAfkLYjk4OODr68vhw4fp1q3bA9/LvR6/fYph165d1KpVy3TKKyQkhOzsbJYsWUJiYiKdOnUyHVPUz8Tt/ztra+tS++zcdvu0ktFoLDCIdf/+/djb29OwYcN7Hrtz506uX7/O6tWrC7zPuLi4EtdTu3Ztjh49iqIoBdq+sM+QqLxkzIioEHbs2FHoX2MbN24EzNMlHBoairOzMx9//DG5ubl3Pf4w01Vv8/X1Zd++feTk5Ji2bdiwgYsXL5bo+Vq1akXdunX56quv7go5/2wvBwcHgEKD0D/pdDoeeeQR1q1bx7lz50zbExMTWbp0KR07dizy6aqSunHjBnv37sXT09M0bXvgwIFcvnyZefPm3bV/ZmamaRwI5L/Xe73PkJAQ9u/fz44dO0xhxM3NjcaNG/Ppp5+a9rmtqJ+J6tWr06VLF+bMmVNoMDbHZ+e2AQMGkJiYyOrVq03bkpKSWLlyJb17977vOju3ezr++dnIycnh22+/LXE9PXv2JD4+nlWrVpm2ZWRkMHfu3BI/p6h4pGdEVAgTJkwgIyODJ554Aj8/P3Jycti7dy/Lly+nTp06jB49+qFfw9nZmVmzZjF8+HBatWrF4MGDcXd358KFC/zyyy906NCBb7755qFeY8yYMaxatYpHH32UgQMHcubMGRYvXmz6C7y4tFots2bNonfv3gQEBDB69Gi8vLw4ceIEx44d47fffgOgdevWQP7qsKGhoeh0unsuUf/hhx+yZcsWOnbsyAsvvICVlRVz5swhOzu70DUmHtaqVatwdHREURTi4+P5/vvvuXnzJrNnzzb9pT18+HBWrFjBc889x44dO+jQoQMGg4ETJ06wYsUKfvvtN1MvWevWrdm6dSvTp0/H29ubunXrmqYjh4SE8NFHH3Hx4sUCoaNTp07MmTOHOnXqULNmTdP24nwmZs6cSceOHfH392fs2LHUq1ePxMREIiIiuHTpEocPHzZLew0YMIB27doxevRoYmNjTSuwGgwG3n///fse2759e6pUqcLIkSN56aWX0Gg0LFq06KFOu4wdO5ZvvvmGESNGEBUVhZeXF4sWLcLe3r7Iz/HNN9+QnJxMfHw8AD///DOXLl0C8n/2XVxcSlyfKCfUmcQjhHn9+uuvytNPP634+fkpjo6Oio2NjVK/fn1lwoQJSmJiYoF97zW198CBAwX2uz199s6phzt27FBCQ0MVFxcXxdbWVvH19VVGjRql/Pnnn/et8fbzrVy58r77ffHFF0qNGjUUvV6vdOjQQfnzzz/vObX3zueKi4srdOrj7t27lR49eihOTk6Kg4OD0rx5c2XGjBmmx/Py8pQJEyYo7u7uikajKTDNlzum9ipK/hTX0NBQxdHRUbG3t1e6du2q7N27t8A+xW3XOxU2tdfBwUEJDg4uME30tpycHOXTTz9VmjZtquj1eqVKlSpK69atlffff19JSUkx7XfixAmlU6dOip2dnQIU+CykpqYqOp1OcXJyUvLy8kzbFy9erADK8OHDC621qJ+JM2fOKCNGjFA8PT0Va2trpUaNGsrjjz+urFq1ymztpiiKcuPGDeWZZ55RqlWrptjb2yudO3e+6/nuZc+ePUq7du0UOzs7xdvb2zRN/s7X7ty5s9K0adO7jh85cqRSu3btAtvOnz+v9OnTR7G3t1fc3NyUl19+Wdm0aVOR30/t2rUfOC1eWDaNoshIIyGEEEKoR8aMCCGEEEJVEkaEEEIIoSoJI0IIIYRQlYQRIYQQQqhKwogQQgghVCVhRAghhBCqkkXPHsBoNBIfH4+Tk1OJrnIqhBBCVFaKopCWloa3t3eByxPcScLIA8THx5fJtTaEEEKIiurixYsFVi++k4SRB3BycgLyG7K0r7khhBBCVCSpqan4+PiYvkvvRcLIA9w+NePs7CxhRAghhCiBBw1zsKgBrH/88Qe9e/fG29sbjUbD2rVrH3jMzp07adWqFXq9nvr16xMeHl7qdQohhBCi6CwqjKSnp9OiRQtmzpxZpP3j4uLo1asXXbt2JTo6mldeeYUxY8aYrlQqhBBCCPVZ1Gmaxx57jMcee6zI+8+ePZu6devyxRdfANC4cWN2797Nl19+SWhoaGmVKSxMnsHIzYxcbqTncDMjh1yDkTyjgsGgkGdU0FtpcdBbYW+jw1FvRRV7G5ztrGR2lRBCmIlFhZHiioiIoHv37gW2hYaG8sorr9zzmOzsbLKzs033U1NTS6s8UYbyDEZOJqZxKvEWZ5PSiUtKJy7pFpduZpKSmUtxr11tb6PD29UOLxdbalaxx8/TKf/m5YyLnXXpvAkhhKigKnQYSUhIwMPDo8A2Dw8PUlNTyczMxM7O7q5jpk2bxvvvv19WJYpScjM9h4iz1zl4/iaHLyUTczmFrFzjPffXaMDVzpoqDjbY6LRY6TTotFp0GsgxGEnPNpCenZd/yzGQkWPg9NVbnL56667nquFqR8targTVq0a7ulWpX91RelGEEOI+KnQYKYkpU6YwceJE0/3b05JE+WYwKhy6cJM//rrG76eSOHIp+a7eDidbKxp7OePr7kBdNwfqujlSq6o91RxtqGJvg05btMCQmWPgSkomV1KyuJycyfnr6ZxMSOP4lTQuJ2eabhuOXAGgqoMNHeq70aOJB10aueNsKz0nQgjxTxU6jHh6epKYmFhgW2JiIs7OzoX2igDo9Xr0en1ZlCcektGoEHXhJhsOx7PxaALX0rILPN7Iw4nAulUJ8HGlhY8r9dwc0BYxcNyPnY2Oeu6O1HN3vOuxlMxcYuNTOXDuBvvjrhN1/iY30nP4+XA8Px+Ox1qnoV29aoQ29eTx5l642ts8dD1CCGHpKnQYCQ4OZuPGjQW2bdmyheDgYJUqEuZw/no6P0ZeZF30Za6kZJm2O9ta0amhe/6tgTueLrZlXpuLnTXBvtUI9q0GNCAnz8jhS8lsO36VLbEJnLmWzq5TSew6lcQHP8fSrXF1nmxVk86N3LHWWdTkNiGEMBuNohR36J56bt26xenTpwFo2bIl06dPp2vXrlStWpVatWoxZcoULl++zA8//ADkT+1t1qwZ48eP5+mnn2b79u289NJL/PLLL0WeTZOamoqLiwspKSmy6JmKcvKMbD2eyNL9F9h9Osm03VFvxSNNPejd3JsO9d2wsSrfX+hnr91ic2wi66Pjib3yv8HRbo42DG5bi6fa1VYlRAkhRGko6neoRYWRnTt30rVr17u2jxw5kvDwcEaNGsW5c+fYuXNngWNeffVVYmNjqVmzJu+88w6jRo0q8mtKGFFXSmYuS/dfYMGeOK7+fRpGo4FODdwZEuhDl0bVsbXWqVxlycTGp/LTwUusi75M0q0cAKy0Gh7z92J0hzq09HGVga9CCItWIcOIGiSMqCMhJYv5e+JYuv8Ct7LzAHB30jOwTU0Gt62FT1V7lSs0n1yDka2xiSzYc47IczdM29vUrsJL3RoQ0sBNQokQwiJJGDETCSNl62pqFt/sOM2PkRfINeR/NBt6OPJsJ196t/Au96dhHtbRyymE7z3H+uh4cgz5U5EDfFx5uVsDujRyl1AihLAoEkbMRMJI2biZnsPs38+wMOKcaT2QwDpVea5LPbo0rG6WWTCWJDE1izm/n2Vp5HlTe7So6cKUno1pV6+aytUJIUTRSBgxEwkjpSsr18D3u+OYtfOM6XRMq1quTAptRHtfN5WrU9+1tGy+23WWHyLOk5lrAKCbX3XefMyPBh73vyS3EEKoTcKImUgYKR2KorDpaAIfbTzOpZuZADT2cub10IZ0bVRdTkfcIelWNl9vPcXSyAsYjApaDQxq68OkRxpRzVHWxRFClE8SRsxEwoj5xcan8v7Px9gflz9Y09PZljcf86NPC+9KdzqmuM5cu8Wnv55gc2z+Yn4udta8HtqIIYG1iryCrBBClBUJI2YiYcR8MnLy+HrrKb7bHYfh76vhPtvZl+c618PepkKvv2d2kXE3CFt/jON/r1XSvKYLU/s2o4WPq7qFCSHEP0gYMRMJI+ax8+RV3l571HRKpqe/J2/1bEzNKhVnim5ZyzMYWbzvPF9s/ou07Dw0GhjRrjaTH/XDQS/hTgihPgkjZiJh5OHcSM/h/Z+PsS46HgBvF1um9mtGt8YeDzhSFNXVtCw+2XiC1YcuA1Czih2fPtmcDvVlALAQQl0SRsxEwkjJbY1N5M3VMSTdykargdEd6jKxR0P5q72U7Dp1jTd/iuFycn7v05BAH6b0bCxXCRZCqEbCiJlIGCm+1KxcPvg5llVRlwBoUN2Rz//dQsYzlIFb2Xl8tukEP0ScB6CGqx3TB7YgSNYmEUKoQMKImUgYKZ59Z68zcXk08SlZaDQwNqQeE3s0tNjrx1iq/Wev8/qqI1y4kYFGA8919uXV7g0r/Aq2QojyRcKImUgYKZo8g5H/bj/NN9tPYVSgVlV7vhjYgrZ1qqpdWqV1KzuPD34+xoo/83uomtVw5qtBLalf3VHlyoQQlYWEETORMPJgl5MzeWXZIQ6cuwnAv1vX5L0+TWVsSDmx6egV3lwdQ3JGLnbWOqb2a8aA1jXVLksIUQlIGDETCSP3t/lYAq+vOkJKZi6Oeis+eqIZfQNqqF2WuENiahavrTjM7tNJQH5g/KBvM+xs5PSZEKL0FPU7VE4gixLJMxiZ9utxxi2KIiUzlxY1XfjlpY4SRMopD2dbFj4dyMQeDdFqYGXUJfrO3M3pq2lqlyaEEBJGRPFdS8tm+PeRzPn9LABPd6jLyufaU7uag8qVifvRaTW81K0Bi8cE4eao56/EW/T5Zg8bjsSrXZoQopKTMCKKJer8DR6fsYuIs9dxsNExc2gr3u3dRGZpWJD2vm5sfLkj7X2rkZFj4MWlh5j263EMRjljK4RQh3yDiCL7MfICg+fuIzE1m/rVHVn3Ygd6NfdSuyxRAtWdbPnh6UCe7VQPgDm/n2XUgkhupueoXJkQojKSMCIeKNdg5N11R5myOoZcg0Ivfy/Wje9A/epOapcmHoKVTsuUno2ZMaQldtY6dp1Kovc3u00X3xNCiLIiYUTc1430HEZ8H2la0fP10EZ8M7SlTNutQHq38GbN+PbUqmrPpZuZPDlrL1tiE9UuSwhRiUgYEfd0KjGNvjN3m8aHzBvRhvFd66PRaNQuTZiZn6cz61/sQIf6+eNIxi36kzm/n0Fm/gshyoKEEVGo3aeS6D9rLxdvZFKrqj1rxnegRxO50m5F5mpvQ/joQJ5qVwtFgWm/nuD1VUfIzjOoXZoQooKTMCLusizyAqMWRJKWlUfbOlVYO74DDT1kfEhlYK3TMrVvM97v0xStBlZFXWL495EkZ8jAViFE6ZEwIkyMRoVPfj3Bm6tjyDMq9AvwZvGYIKo62KhdmihDGo2Gke3rsGB0IE56KyLjbvDkrL1cvJGhdmlCiArK4sLIzJkzqVOnDra2tgQFBREZGXnPfcPDw9FoNAVutra2ZVit5cjOM/DSskPM/v0MAC93a8CXgwLQW8ly4ZVV54burHw+GC8XW85cS+eJb/dy5FKy2mUJISogiwojy5cvZ+LEiYSFhXHw4EFatGhBaGgoV69evecxzs7OXLlyxXQ7f/58GVZsGVKzchk5P5INR65grdMwfWALXu3RUAaqCvw8nVnzQgcaezmTdCubQXP2se24zLQRQpiXRYWR6dOnM3bsWEaPHk2TJk2YPXs29vb2zJ8//57HaDQaPD09TTcPDxmE+U8JKVkMnB3BvrM3cNRbsWBUIP1byRVdxf94utiy4tl2hDRwIzPXwNgf/mT5gQtqlyWEqEAsJozk5OQQFRVF9+7dTdu0Wi3du3cnIiLinsfdunWL2rVr4+PjQ9++fTl27Nh9Xyc7O5vU1NQCt4rq9NU0+n+7hxMJabg76Vn+bDs6NnBTuyxRDjnZWjN/VFsGtK6JUYE3foph5o7TMvVXCGEWFhNGkpKSMBgMd/VseHh4kJCQUOgxjRo1Yv78+axbt47FixdjNBpp3749ly5duufrTJs2DRcXF9PNx8fHrO+jvDh04SYDZkcQn5JFPXcHVj/fnqbeLmqXJcoxa52W/xvQnOe7+ALwf7+d5IMNsRjlmjZCiIdkMWGkJIKDgxkxYgQBAQF07tyZ1atX4+7uzpw5c+55zJQpU0hJSTHdLl68WIYVl41dp64x7Lv9JGfkEuDjyqrn2uNT1V7tsoQF0Gg0vPGoH+883gSABXvO8cryaHLyjCpXJoSwZBazprebmxs6nY7ExIKD5xITE/H09CzSc1hbW9OyZUtOnz59z330ej16vf6hai3PNsZc4eVlh8g1KIQ0cGP2U61laXdRbM90rIubow2vrTjM+sPxpGblMmtYa+xsZPaVEKL4LKZnxMbGhtatW7Nt2zbTNqPRyLZt2wgODi7ScxgMBmJiYvDyqpxXmv0x8gLjlx40Xezuu5FtJIiIEusbUIPvR7XF1lrLzpPXGDk/ktSsXLXLEkJYIIsJIwATJ05k3rx5LFy4kOPHj/P888+Tnp7O6NGjARgxYgRTpkwx7f/BBx+wefNmzp49y8GDB3nqqac4f/48Y8aMUestqGbeH2eZsjoGRYGhQbX475CWsoaIeGidG7qz+JkgnGytiDx3g6Hz9nH9VrbaZQkhLIxF/Vk8aNAgrl27xrvvvktCQgIBAQFs2rTJNKj1woULaLX/y1c3b95k7NixJCQkUKVKFVq3bs3evXtp0qSJWm+hzCmKwtfbTvHV1lMAPN/Fl8mhjWQNEWE2bepU5cex7Rg5P5Kjl1MZOCeCxWOC8HKxU7s0IYSF0CgyN+++UlNTcXFxISUlBWdnZ7XLKRZFUZj26wnm/nEWgNdDGzG+a32VqxIV1Zlrt3jqu/1cScnCp6odS8e0k4HRQlRyRf0OtajTNKLojEaFt9ceNQWRdx9vIkFElCpfd0dWPhdM7Wr2XLyRyaA5EcQlpatdlhDCAkgYqYAMRoXJPx1hyf4LaDTwSX9/nu5YV+2yRCVQs4o9K54NxtfdgfiULAbNieBUYpraZQkhyjkJIxVMnsHIayuiWRV1CZ1Ww5cDAxgcWEvtskQl4uFsy/Jng/HzdOJqWjaD5+4jNr7irmQshHh4xR4zkpyczJo1a9i1axfnz58nIyMDd3d3WrZsSWhoKO3bty+tWlVhSWNGcg1GXl0ezYYjV7DSavh6cEt6Na+c05iF+m6m5zBifiQxl1NwsbNmyZggmtWQVX6FqEzMPmYkPj6eMWPG4OXlxYcffkhmZiYBAQF069aNmjVrsmPHDnr06EGTJk1Yvny5Wd6EKLqcPCMTlh4yXXl35rBWEkSEqqo42LB4TBAta7mSkpnL0Hn7iLmUonZZQohyqMhTe1u2bMnIkSOJioq659TYzMxM1q5dy1dffcXFixeZNGmS2QoV95aTZ2T80oNsiU3ERqdl9vBW/MtPrk4s1OdiZ80PTwcyasEBos7fZOh3+1j8TBAtfFzVLk0IUY4U+TTN9evXqVatWpGfuLj7l1fl/TRNTp6RF5YcZOvxRPRWWuaOaEPnhu5qlyVEAbey8xi9IJID527ipLfih2cCaVmritplCSFKmdlP0xQ1WNzONhUhiJR3dwaReRJERDnlqLcifHQggXWrkpadx/DvIzl44abaZQkhyokSzaYZNWoU6el3rx9w7tw5OnXq9NBFiQfLDyJRBYJIJwkiohxz0FsRProt7epV5VZ2HiO/j+SQBBIhBCUMI4cPH6Z58+ZERESYti1cuJAWLVrg5uZmtuJE4f7XI3JVgoiwKPY2Vswf1Zagv3tIRnwfSfTFZLXLEkKorERhJDIykv79+9OlSxfeeustBg4cyIsvvsjnn3/OmjVrzF2j+Idcg5EXlx6UHhFhsextrFgwuu0/Ttns58ilZLXLEkKo6KGuTRMWFsbUqVOxsrLi999/Jzg42Jy1lQvlaQBrrsHISz8e4tejCdhYaflOgoiwYOnZeYz6e1Crs60VS8a0w7+mrEMiREVSqtemyc3N5bXXXuPTTz9lypQpBAcH079/fzZu3FjigsX95RmMvLI8Oj+I6LTMGd5agoiwaA56KxaMDqRN7SqkZuXx1Pf7ORYv65AIURmVKIy0adOG9evXs3PnTj766CN27tzJK6+8Qv/+/XnhhRfMXWOlZzAqTFxxmF/+XtBs1lOt6NqoutplCfHQHPVWhD8daFoY7anv9nMyQa5lI0RlU+IwEh0dTbt27QDQaDS88cYbRERE8Mcff5i1wMrOaFR4fdVh1h+Ox0qrYebQVnRrLAuaiYrDUW/FwqcDaV7ThZsZuQz7bh+nr0ogEaIyeagxI4XJycnBxsbGnE+pKjXHjBiNCm+tiWHZgYvotBq+GdKSx/xliXdRMaVk5DL0u30ci0/F3UnP8nHtqOfuqHZZQoiHUKpjRv71r3+RknL3ud1Tp07J1F4zURSFsPXHWHbgIloNfDkoQIKIqNBc7K1Z/EwQfp5OXEvLZui8/Vy4nqF2WUKIMlCinhGtVkuzZs2wsip4aZuEhAQUReHKlStmK1BtavSMKIrCh78c5/vdcWg08PmAFjzZumaZvLYQart+K5vBc/dx6uotarjaseK5YGq42qldlhCiBIr6HVrkC+XdKTQ0FEfH/3WhajQanJycCA0NLelTCvKDyGe/neT73XEATHvCX4KIqFSqOepZMjaIwXP2cTYpnaHz9rHi2WA8nG3VLk0IUUpK3DOSkJBA9eoVf0ZHWfeMfL31FF9u/QuAqX2bMjy4Tqm/phDl0ZWUTAbOieDijUx83R1YNi4Ydye92mUJIYqhVMeMQH5PiDCvOb+fMQWRt3s1liAiKjUvFzuWjmmHt4stZ66l89R3+7mZnqN2WUKIUlDinpH27dvfc9bM9u3bH7qw8qKsekbC98Tx3s+xALwe2ojxXeuX2msJYUnOJaUzcE4EV9OyaVbDmSVj2uFiZ612WUKIIij1MSNNmzbF3t6+pIeLf1gWecEURCb8q74EESH+oY6bA0vHBjFozj6OXk5l1IJIFj0ThKO+xL++hBDlTIl6Rt5//30mTZqEg4NDadRUrpR2z8iaQ5eYuOIwigLjOtVjymN+cgpMiELExqcyZN4+UjJzCaxblYWjA7Gz0aldlhDiPkp1zEhYWJhqQWTmzJnUqVMHW1tbgoKCiIyMvO/+K1euxM/PD1tbW/z9/cvV9XM2xlzhtb+DyIjg2hJEhLiPJt7OLHomECe9FZFxNxi36E+ycg1qlyWEMINih5HDhw/z4Ycf8u2335KUlFTgsdTUVJ5++mmzFXen5cuXM3HiRMLCwjh48CAtWrQgNDSUq1evFrr/3r17GTJkCM888wyHDh2iX79+9OvXj6NHj5ZajUW17XgiL/14CKMCA9vU5L3eTSWICPEAzWu6smB0W+xtdOw6lcSLSw+SazCqXZYQ4iEV6zTN5s2b6d27Nw0aNCAtLY309HRWrlxJ165dAUhMTMTb2xuDoXT+WgkKCqJt27Z88803ABiNRnx8fJgwYQJvvvnmXfsPGjSI9PR0NmzYYNrWrl07AgICmD17dpFeszRO0+w6dY1nwv8kx2CkTwtvvhwUgE4rQUSIotp7JonRCw6QnWekl78XXw8OwEpX4smBQgjg+91xPNLEA5+q5hsPWiqnad577z0mTZrE0aNHOXfuHJMnT6ZPnz5s2rTpoQt+kJycHKKioujevbtpm1arpXv37kRERBR6TERERIH9IX+xtnvtD5CdnU1qamqBmzmdSEhl7A/5QSS0qQdfDGwhQUSIYmrv68bs4a2x1mn4JeYKk386gtFo1stsCVGpfLvzNFM3xDJwTgSpWbll/vrFCiPHjh0znYbRaDRMnjyZOXPmMGDAgAK9D6UhKSkJg8GAh0fBK9Z6eHiQkJBQ6DEJCQnF2h9g2rRpuLi4mG4+Pj4PX/w/1Hd3JLSpJ10aufPfIS2xlr/mhCiRro2qM2NIK3RaDasPXubtdUcx83U/hagUFuyJ47NNJwEY2b4OzrZlP3W+WN+Eer2e5OTkAtuGDh3Kd999x6BBg1izZo05a1PFlClTSElJMd0uXrxo1ue30mmZPjCA2U+1Rm8lMwGEeBiPNvPky0EBaDSwdP8Fpm44LoFEiGJYuv8C7/+9tMTL3RrwXGdfVeoo1kT9gIAAduzYQevWrQtsHzx4MIqiMHLkSLMW909ubm7odDoSExMLbE9MTMTT07PQYzw9PYu1P+QHLr2+dJec1mk16LQSRIQwhz4tvMnKNTB51RHm74nDzkbL66F+apclRLm3+uAl/rM2BoBnO9Xjle4NVKulWD0jzz//PJcvXy70sSFDhhAeHk6nTp3MUtidbGxsaN26Ndu2bTNtMxqNbNu2jeDg4EKPCQ4OLrA/wJYtW+65vxDCMg1s48PUvk0BmLnjDDO2nVK5IiHKt40xV5i08n9LS7yp8tISJVr0TC3Lly9n5MiRzJkzh8DAQL766itWrFjBiRMn8PDwYMSIEdSoUYNp06YB+VN7O3fuzCeffEKvXr1YtmwZH3/8MQcPHqRZs2ZFes2yvlCeEKLkvtt1lg9/OQ7Af3o2ZmyneipXJET5syU2kecXR5FnVBjYpiaf9G+OtpQmUph9OXhFUVRfB2PQoEFcu3aNd999l4SEBAICAti0aZNpkOqFCxfQav/X2dO+fXuWLl3K22+/zVtvvUWDBg1Yu3ZtkYOIEMKyjAmpR2aOgS+2/MVHG4+jt9YyQi44KYTJ739dY/ySg+QZFfoGeDOtFINIcRS5Z6RJkya8++679O/f/54XyAM4deoU06dPp3bt2oWu/WFppGdECMuiKAr/99tJvt15BoBPn/RnUNtaKlclhPoizlxn1IJIsvOMPNbMkxlDWpb6+jxm7xmZMWMGb7zxBi+88AI9evSgTZs2eHt7Y2try82bN4mNjWX37t0cO3aMF198keeff94sb0QIIYpDo9HwemgjsnKNzN8Tx5urY9Bb6ejXsobapQmhmqjzN3hmYf5Cgd38qvP14NIPIsVR7DEju3fvZvny5ezatYvz58+TmZmJm5sbLVu2JDQ0lGHDhlGlSpXSqrfMSc+IEJZJURTeWXeUxfsuoNXAjCGt6NXcS+2yhChzhy8m89R3+0nLziOkgRvzRrTB1rpsZnQW9TvUogawqkHCiBCWy2hUeOOnI6yMuoSVVsOsp1rTo4nHgw8UooI4ejmFofP2kZqVR1DdqoSX8dWuS/WqvUIIYQm0Wg2fPNmcfgHe5BkVxi85yI4ThV9YU4iK5kRCKsO/309qVh5taldh/qi2ZRpEiqNYi57907Zt29i2bRtXr17FaCx41cz58+c/dGFCCGEOOq2Gz//dghyDkY0xCTy7OIrvR7YhpIG72qUJUWpOX01j2Lz93MzIpYVP/tWuHfQl/sovdSXqGXn//fd55JFH2LZtG0lJSdy8ebPATQghyhMrnZavB7ekRxMPcvKMjFn4J3vPJKldlhCl4uy1Wwydt5/r6Tk09Xbmh9GBOKlwvZniKNGYES8vLz777DOGDx9eGjWVKzJmRIiKIzvPwPOLD7L9xFXsrHWEj25LUL1qapclhNmcS0pn0NwIElOz8fN04sex7ajicO/lOEpbqY4ZycnJoX379iUuTggh1KC30vHtsFZ0auhOZq6B0eEHiDp/Q+2yhDCLC9czGDJvH4mp2TT0cGTJmCBVg0hxlCiMjBkzhqVLl5q7FiGEKHW21jrmDm9Nh/rVyMgxMHL+AaLOy+llYdku3sgPIldSsvB1d2DJmHZUcyzdi76aU4lGs2RlZTF37ly2bt1K8+bNsbYueC5q+vTpZilOCCFKg621ju9GtOXp8ANEnL3OyPmR/PBMIK1qVZw1kkTlcTk5kyHz9nE5OZN6bg78OLYd7k6WE0SghGNGunbteu8n1GjYvn37QxVVnsiYESEqroycPJ4OP8C+szdw0lvxwzOBtJRAIizIpZv5PSIXb2RS182BZePa4eFsq3ZZJrLomZlIGBGiYsvIyWPUggNExuUHkkVjggjwcVW7LCEe6NLNDAbP3celm5nUqWbPj+Pa4eVip3ZZBciiZ0IIUQT2NlYsGNWWwDpVScvOY/h3+zl0QcaQiPLNEoJIcRS5Z6R///6Eh4fj7OxM//7977vv6tWrzVJceSA9I0JUDunZeYwOz+8hcdRbsfDptrSuXVXtsoS4y51BZNm4YDxdys+pmX8ye8+Ii4sLGo3G9O/73YQQwtI46K0IH92WdvWqcis7jxHfR3LgnEz7FeXLhesZDJpjGUGkOEo0ZiQzMxOj0YiDgwMA586dY+3atTRu3JjQ0FCzF6km6RkRonLJzDHwzMID7D1zHXsbHQtGycJoonyIS0pnyNx9JKRmUc/NgaVj25X7IFKqY0b69u3LokWLAEhOTqZdu3Z88cUX9OvXj1mzZpWsYiGEKAfsbHR8P7ItHeu7kZFjYNSCA+w5LUvHC3WdvprGoDkRJKRmUb+6I8vGlf8gUhwlCiMHDx4kJCQEgFWrVuHh4cH58+f54Ycf+O9//2vWAoUQoqzZ2ej4bmQbOv9jpdYdJ+Vqv0IdJxPSGDx3H1fT8pd4XzauHdXL0fRdcyhRGMnIyMDJyQmAzZs3079/f7RaLe3ateP8+fNmLVAIIdRga61j7ojWdG+cf3G9cT/8yW/HEtQuS1QyRy+nMHhuBEm3cmji5czSse1ws6CVVYuqRGGkfv36rF27losXL/Lbb7/xyCOPAHD16lUZVyGEqDD0VjpmPdWKXv5e5BoUXlhykJ8Px6tdlqgkos7fYMjcfdzMyKV5TReWjg2iqoVca6a4ShRG3n33XSZNmkSdOnUICgoiODgYyO8ladmypVkLFEIINVnrtHw9OID+LWtgMCq8vOwQKw5cVLssUcHtOZ3EU99FkpadR2CdqiwZE4SrfcUMIvAQK7AmJCRw5coVWrRogVabn2kiIyNxdnbGz8/PrEWqSWbTCCEAjEaF/6yN4cfI/CDyzuNNeKZjXZWrEhXRtuOJPL/kIDl5RkIauDF3eBvsbHRql1Uishy8mUgYEULcpigKH288zrxdcQC83K0Br3RvYFqDSYiHtS76Mq+tOEyeUaFHEw++GdoSvZVlBhGQ5eCFEMLsNBoNb/VszGs9GgLw9bZTTN1wHKNR/qYTD29RxDleWR5NnlGhb4A33w5rZdFBpDgsJozcuHGDYcOG4ezsjKurK8888wy3bt267zFdunRBo9EUuD333HNlVLEQoiLSaDRM6NaA93o3AWD+njgmrTpMrsGocmXCUimKwtdbT/HOumMoCowIrs2XAwOw1lnMV/RDs1K7gKIaNmwYV65cYcuWLeTm5jJ69GjGjRvH0qVL73vc2LFj+eCDD0z37e3tS7tUIUQlMKpDXZxsrZn80xFWH7zMzfQcZg5rhb2NxfxaFeWA0ajwwYZYwveeAyrvqT+L+Kk5fvw4mzZt4sCBA7Rp0waAGTNm0LNnTz7//HO8vb3veay9vT2enp5lVaoQohJ5snVNXO2tGb/0IDtOXmPYd/tZMKpthZ71IMwnJ8/IpJWHWf/3dPGw3k0Y3aFyDoq2iD6giIgIXF1dTUEEoHv37mi1Wvbv33/fY5csWYKbmxvNmjVjypQpZGRk3Hf/7OxsUlNTC9yEEOJeujX2YMmYIFzsrDl0IZkBsyOIT85UuyxRzqVl5TI6PJL1h+Ox0mr4clCLShtEwELCSEJCAtWrVy+wzcrKiqpVq5KQcO8VEYcOHcrixYvZsWMHU6ZMYdGiRTz11FP3fa1p06YVuAKxj4+PWd6DEKLial27KiufC8bT2ZbTV2/R/9u9HL8if8iIwl1NzWLgnH3sOX0dBxsd80e15YmWNdUuS1WqhpE333zzrgGmd95OnDhR4ucfN24coaGh+Pv7M2zYMH744QfWrFnDmTNn7nnMlClTSElJMd0uXpTFjYQQD9bQw4mfXmhP/eqOJKRm8e/ZEew6dU3tskQ5c/rqLZ74O6y6OepZ/mwwnRq6q12W6lQdM/Laa68xatSo++5Tr149PD09uXq14EWq8vLyuHHjRrHGgwQFBQFw+vRpfH19C91Hr9ej11e8df+FEKWvhqsdPz3XnmcX/8m+szcYveAAH/f3Z2Ab6WEVEHHmOs8u+pPUrDzqujmwcHQgtarJpApQOYy4u7vj7v7gRBgcHExycjJRUVG0bt0agO3bt2M0Gk0Boyiio6MB8PLyKlG9QgjxIC721ix8OpDJq46wLjqeyauOcOlmJq9WwhkS4n9WRV1iyuoj5BoUWtVyZd6INlSrgBe8KymLGDPSuHFjHn30UcaOHUtkZCR79uzhxRdfZPDgwaaZNJcvX8bPz4/IyEgAzpw5w9SpU4mKiuLcuXOsX7+eESNG0KlTJ5o3b67m2xFCVHB6Kx1fDgxgfNf8Htj/bjvFS8uiyco1qFyZKGtGo8Lnv51k0srD5BoUHm/uxdKx7SSI3MEiwgjkz4rx8/OjW7du9OzZk44dOzJ37lzT47m5uZw8edI0W8bGxoatW7fyyCOP4Ofnx2uvvcaTTz7Jzz//rNZbEEJUIlqthtdD/fj0SX+stBp+PhzPoLn7uJqapXZpooxk5hh4adkhvtlxGoAXu9bnv4NbYmtdOVZVLQ65Ns0DyLVphBAPK+LMdZ5fEkVyRi5eLrbMG9GGZjVc1C5LlKL45EzGLfqTo5dTsdJqKu3YIbk2jRBClBPBvtVY+0IHfN0duJKSP9Nmw5F4tcsSpeTPczfo880ejl5OpaqDDYvHBFXKIFIcEkaEEKIM1HFzYPULHQhp4EZmroEXlx7ik19PYJCL7FUoyw9cYMi8fSTdysbP04l14zvQrl41tcsq9ySMCCFEGXGxs2bBqLY826keALN/P8OoBZEkZ+SoXJl4WNl5Bt5aE8MbP8WQa1B4rJknq19oj09VmbpbFBJGhBCiDFnptEzp2Zj/DmmJnbWOXaeS6P3Nbo7Fp6hdmiihSzcz+PfsCJbuv4BGAxN7NGTmULloYnFIGBFCCBX0aeHN6hfaU6uqPRdvZPLEt3tZsv88MqfAsvz+1zUen7GbI5dScLXP7/l6qVsDtFpZU6Y4JIwIIYRKGns5s/7FDnRvXJ2cPCP/WXOUl5dFcys7T+3SxAPkGYxM33zy79NsuTSv6cKGCR3p0qj6gw8Wd5EwIoQQKnK1t2HeiDa81dMPnVbD+sPx9Jmxm9h4udBeeXXpZgaD5+7jv9tPoygwJLAWK54NpmYVGR9SUrLOyAPIOiNCiLISdf4GLy49xJWULGx0WiY/2oinO9SVLv9y5NeYK7zx0xFSs/Jw0lvxUX9/+rTwVruscquo36ESRh5AwogQoizdTM/h9VWH2Xo8/+KgHepX44t/B+DpYqtyZZXbrew8Pvollh8j86/kHuDjyn8Ht5QL3T2AhBEzkTAihChriqKwNPICUzfEkpVrxMXOmmn9/enpLxf5VMO+s9eZtPIwl25mAvBcZ19ee6Qh1joZ6fAgEkbMRMKIEEItZ67d4pVl0cRczp/228vfi/f7NsVNLrJWJrJyDfzfbyeZvycORYEarnZ8/u8WBPvKImZFJWHETCSMCCHUlJNnZMb2U3y78wwGo0IVe2ve69OUPi280WhkLElp2Xf2Om+tieHstXQABrf14e3Hm+Col7VDikPCiJlIGBFClAdHL6fw+qojHL+SP8ume+PqvN+3GTVc7VSurGJJzshh2sYTLP8zf2xIdSc9nz7ZnK5+MmW3JCSMmImEESFEeZFrMDJ75xn+u/0UuQYFO2sdE7rVZ0zHethYyfiFh6EoCusPxzN1QyxJt/KX5x8aVIs3HvXDxc5a5eosl4QRM5EwIoQob/5KTOPtNUeJPHcDgHruDkzt24wO9d1UrswyHYtP4f2fY4mMy2/PBtUd+bi/P23rVFW5MssnYcRMJIwIIcojRVFYc+gyH288bvpLPrSpB5Mf9cPX3VHl6ixD0q1svth8kmUHLqIoYGutZXyX+jzb2Vd6msxEwoiZSBgRQpRnKZm5fLnlL36IOIdRAZ1Ww9DAWrzUrQHuTjLrpjDp2XmE7z3H7J1nSPt76f3eLbx58zE/GYNjZhJGzETCiBDCEvyVmManv55g24n8xdIcbHSMCanH0x3rypiHv2XlGli6/wLf7jxt6k1qVsOZsN5N5ZRMKZEwYiYSRoQQlmTvmSSmbTxhWpvESW/FqA51eLpDXao42KhcnTqycg2sjLrEtztOcyUlC4BaVe15tUcD+raoIcvtlyIJI2YiYUQIYWmMRoWNR68wY9tpTiamAfk9JU8F12ZU+zp4uVSOUxHJGTksijhP+N5zXE/P7wnxcrFlwr8a8O82NWUF1TIgYcRMJIwIISyV0aiwOTaB/247Tezf65PotBoebebJ6PZ1aF27SoVcOO301Vss3neeFX9eJCPHAOSvnjo2pC6DA2tha61TucLKQ8KImUgYEUJYOkVR2Hb8Kt/tPsu+szdM2/1ruDCwrQ99mnvjYm/Z40qy8wxsOprAkv0XTFN0ARp7OfNc53r09PeSnhAVSBgxEwkjQoiK5PiVVML3nGNt9GWy84wA2Oi0dG9SnSdb1aRTQ3eL+dI2GBX2n73Oz0eu8OvRKyRn5AKg1UC3xh4Mb1ebkAZuFbL3x1JIGDETCSNCiIroRnoOqw9eYlXUJU4kpJm2O9la0bVRdXo08aBLI3ecbMtXj0lWroED526wNTaRjUcTuJaWbXrMy8WWwW1rMaitD54utipWKW6rcGHko48+4pdffiE6OhobGxuSk5MfeIyiKISFhTFv3jySk5Pp0KEDs2bNokGDBkV+XQkjQoiK7lh8Cj9FXWb94cumKa8A1joNbetUJahuNQLrVqVlLdcyH2+RZzDyV+ItIs5e54+/rrE/7jpZuUbT4y521jza1JPHW3gRXK8aVhbSq1NZVLgwEhYWhqurK5cuXeL7778vUhj59NNPmTZtGgsXLqRu3bq88847xMTEEBsbi61t0VKzhBEhRGVhMCpEX7zJ5thEtsQmmq5Ye5uNTot/TReaeDnT2MsZPy8nGnk44WCmK9mmZ+cRl5TO2aR0Yi4lc/hiCjGXU8jMNRTYz8NZT6cG7vT096JDfTdZLbUcq3Bh5Lbw8HBeeeWVB4YRRVHw9vbmtddeY9KkSQCkpKTg4eFBeHg4gwcPLtLrSRgRQlRWZ67dYu+Z6+w/e539cTcKnBL5p2oONni52uLtYoe3qx2u9tY42FjhoLfCQa/DSqslz2jEYFTIMypk5Rq4kZ7DjfQcrqfncC0tm/PX00lMLfz5nfRWBNRypVMDdzo1dKehh6OMA7EQRf0ONU+cLYfi4uJISEige/fupm0uLi4EBQURERFxzzCSnZ1Ndvb/fiBSU1NLvVYhhCiPfN0d8XV3ZHi72iiKwrnrGRy+mMzxK6kcT0jj+JVUrqVlc/3vUHH08sP/vqzmYENdNwcaeToR4ONKy1qu1HNzlIXJKrgKG0YSEhIA8PDwKLDdw8PD9Fhhpk2bxvvvv1+qtQkhhKXRaDTUdXOgrpsD/VrWMG1PzsghPjmL+ORMrqRkcjk5i7SsXNKz87iVbSA9Ow+DUcFKp0Gn1WCt02Kj01LFwYZqDjZUdbChmqMNtas5ULeag8VPMRYlo2oYefPNN/n000/vu8/x48fx8/Mro4pgypQpTJw40XQ/NTUVHx+fMnt9IYSwJK72Nrja29DEW05ji5JTNYy89tprjBo16r771KtXr0TP7enpCUBiYiJeXl6m7YmJiQQEBNzzOL1ej14vV7oUQgghyoqqYcTd3R13d/dSee66devi6enJtm3bTOEjNTWV/fv38/zzz5fKawohhBCi+CxmPtSFCxeIjo7mwoULGAwGoqOjiY6O5tatW6Z9/Pz8WLNmDZB/fvOVV17hww8/ZP369cTExDBixAi8vb3p16+fSu9CCCGEEHeymAGs7777LgsXLjTdb9myJQA7duygS5cuAJw8eZKUlBTTPpMnTyY9PZ1x48aRnJxMx44d2bRpU5HXGBFCCCFE6bO4dUbKWkpKCq6urly8eFHWGRFCCCGK4fYkkOTkZFxcXO65n8X0jKglLS3/mg0yo0YIIYQombS0tPuGEekZeQCj0Uh8fDxOTk5mW/HvdlKU3hbzkTY1L2lP85M2NS9pT/MrjTZVFIW0tDS8vb3Rau89TFV6Rh5Aq9VSs2bNUnluZ2dn+SEyM2lT85L2ND9pU/OS9jQ/c7fp/XpEbrOY2TRCCCGEqJgkjAghhBBCVRJGVKDX6wkLC5OVXs1I2tS8pD3NT9rUvKQ9zU/NNpUBrEIIIYRQlfSMCCGEEEJVEkaEEEIIoSoJI0IIIYRQlYQRIYQQQqhKwkgpmTlzJnXq1MHW1pagoCAiIyPvu//KlSvx8/PD1tYWf39/Nm7cWEaVWo7itOm8efMICQmhSpUqVKlShe7duz/w/6CyKe5n9LZly5ah0Wjk6teFKG6bJicnM378eLy8vNDr9TRs2FB+9v+huO351Vdf0ahRI+zs7PDx8eHVV18lKyurjKot3/744w969+6Nt7c3Go2GtWvXPvCYnTt30qpVK/R6PfXr1yc8PLz0ClSE2S1btkyxsbFR5s+frxw7dkwZO3as4urqqiQmJha6/549exSdTqd89tlnSmxsrPL2228r1tbWSkxMTBlXXn4Vt02HDh2qzJw5Uzl06JBy/PhxZdSoUYqLi4ty6dKlMq68fCpue94WFxen1KhRQwkJCVH69u1bNsVaiOK2aXZ2ttKmTRulZ8+eyu7du5W4uDhl586dSnR0dBlXXj4Vtz2XLFmi6PV6ZcmSJUpcXJzy22+/KV5eXsqrr75axpWXTxs3blT+85//KKtXr1YAZc2aNffd/+zZs4q9vb0yceJEJTY2VpkxY4ai0+mUTZs2lUp9EkZKQWBgoDJ+/HjTfYPBoHh7eyvTpk0rdP+BAwcqvXr1KrAtKChIefbZZ0u1TktS3Da9U15enuLk5KQsXLiwtEq0KCVpz7y8PKV9+/bKd999p4wcOVLCyB2K26azZs1S6tWrp+Tk5JRViRaluO05fvx45V//+leBbRMnTlQ6dOhQqnVaoqKEkcmTJytNmzYtsG3QoEFKaGhoqdQkp2nMLCcnh6ioKLp3727aptVq6d69OxEREYUeExERUWB/gNDQ0HvuX9mUpE3vlJGRQW5uLlWrVi2tMi1GSdvzgw8+oHr16jzzzDNlUaZFKUmbrl+/nuDgYMaPH4+HhwfNmjXj448/xmAwlFXZ5VZJ2rN9+/ZERUWZTuWcPXuWjRs30rNnzzKpuaIp6+8luVCemSUlJWEwGPDw8Ciw3cPDgxMnThR6TEJCQqH7JyQklFqdlqQkbXqnN954A29v77t+uCqjkrTn7t27+f7774mOji6DCi1PSdr07NmzbN++nWHDhrFx40ZOnz7NCy+8QG5uLmFhYWVRdrlVkvYcOnQoSUlJdOzYEUVRyMvL47nnnuOtt94qi5IrnHt9L6WmppKZmYmdnZ1ZX096RkSF98knn7Bs2TLWrFmDra2t2uVYnLS0NIYPH868efNwc3NTu5wKw2g0Ur16debOnUvr1q0ZNGgQ//nPf5g9e7bapVmknTt38vHHH/Ptt99y8OBBVq9ezS+//MLUqVPVLk0UgfSMmJmbmxs6nY7ExMQC2xMTE/H09Cz0GE9Pz2LtX9mUpE1v+/zzz/nkk0/YunUrzZs3L80yLUZx2/PMmTOcO3eO3r17m7YZjUYArKysOHnyJL6+vqVbdDlXks+ol5cX1tbW6HQ607bGjRuTkJBATk4ONjY2pVpzeVaS9nznnXcYPnw4Y8aMAcDf35/09HTGjRvHf/7zH7Ra+du7OO71veTs7Gz2XhGQnhGzs7GxoXXr1mzbts20zWg0sm3bNoKDgws9Jjg4uMD+AFu2bLnn/pVNSdoU4LPPPmPq1Kls2rSJNm3alEWpFqG47enn50dMTAzR0dGmW58+fejatSvR0dH4+PiUZfnlUkk+ox06dOD06dOmYAfw119/4eXlVamDCJSsPTMyMu4KHLeDniKXYCu2Mv9eKpVhsZXcsmXLFL1er4SHhyuxsbHKuHHjFFdXVyUhIUFRFEUZPny48uabb5r237Nnj2JlZaV8/vnnyvHjx5WwsDCZ2nuH4rbpJ598otjY2CirVq1Srly5YrqlpaWp9RbKleK2551kNs3ditumFy5cUJycnJQXX3xROXnypLJhwwalevXqyocffqjWWyhXitueYWFhipOTk/Ljjz8qZ8+eVTZv3qz4+voqAwcOVOstlCtpaWnKoUOHlEOHDimAMn36dOXQoUPK+fPnFUVRlDfffFMZPny4af/bU3tff/115fjx48rMmTNlaq8lmjFjhlKrVi3FxsZGCQwMVPbt22d6rHPnzsrIkSML7L9ixQqlYcOGio2NjdK0aVPll19+KeOKy7/itGnt2rUV4K5bWFhY2RdeThX3M/pPEkYKV9w23bt3rxIUFKTo9XqlXr16ykcffaTk5eWVcdXlV3HaMzc3V3nvvfcUX19fxdbWVvHx8VFeeOEF5ebNm2VfeDm0Y8eOQn8n3m7DkSNHKp07d77rmICAAMXGxkapV6+esmDBglKrT6Mo0n8lhBBCCPXImBEhhBBCqErCiBBCCCFUJWFECCGEEKqSMCKEEEIIVUkYEUIIIYSqJIwIIYQQQlUSRoQQQgihKgkjQgghhFCVhBEhhBBCqErCiBBCCCFUJWFECCGEEKqSMCKEsDjXrl3D09OTjz/+2LRt79692NjY3HXZcyFE+ScXyhNCWKSNGzfSr18/9u7dS6NGjQgICKBv375Mnz5d7dKEEMUkYUQIYbHGjx/P1q1badOmDTExMRw4cAC9Xq92WUKIYpIwIoSwWJmZmTRr1oyLFy8SFRWFv7+/2iUJIUpAxowIISzWmTNniI+Px2g0cu7cObXLEUKUkPSMCCEsUk5ODoGBgQQEBNCoUSO++uorYmJiqF69utqlCSGKScKIEMIivf7666xatYrDhw/j6OhI586dcXFxYcOGDWqXJoQoJjlNI4SwODt37uSrr75i0aJFODs7o9VqWbRoEbt27WLWrFlqlyeEKCbpGRFCCCGEqqRnRAghhBCqkjAihBBCCFVJGBFCCCGEqiSMCCGEEEJVEkaEEEIIoSoJI0IIIYRQlYQRIYQQQqhKwogQQgghVCVhRAghhBCqkjAihBBCCFVJGBFCCCGEqv4f5+3fH9plDIoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 600x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generating values from 0 to 1\n",
    "x = np.linspace(0, 1, 100)\n",
    "# Calculating the sine of these values\n",
    "y = np.sin(2 * np.pi * x)\n",
    "\n",
    "# Plotting the function\n",
    "plt.figure(figsize=(6, 2))\n",
    "plt.plot(x, y, label='sin(2πx)')\n",
    "plt.title('Sine Function Between 0 and 1')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('sin(2πx)')\n",
    "plt.show()\n",
    "\n",
    "x = x.tolist()\n",
    "y = y.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With neural network it is our task to find a state of a network such that it can transform an input $x$ to the desired out put of $y$, i.e.:\n",
    "\n",
    "$$ x \\rightarrow NN \\rightarrow y $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_result(inp, out, exp, err):\n",
    "    text = f\"\"\"\n",
    "    Input:      {inp}\n",
    "    Output:     {out}\n",
    "    Expected:   {exp}\n",
    "    Error:      {err}\n",
    "    \"\"\"\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of an error is to calculate the difference between output and expected value. This error will dictate how much the weights should be updated and kick off the backpropagation process. This is also an indicator of the model efficiency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Error:  Scalar(w=91.23430790232382)\n"
     ]
    }
   ],
   "source": [
    "preds = [mlp([i]).pop() for i in x]\n",
    "total_error = sum([(y_true - y_pred) ** 2 for y_true, y_pred in zip(y, preds)])\n",
    "print(\"Total Error: \", total_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learning process starts with the Error. Backpropagation from the latest node and back the chain of operations. For this reason we have a Scalar value which keep track of what value comes before. To actually implement this we need to edit the `Scalar` class to enable this functionality. With this feature in place calculating gradients becomes very easy, as each scalar instance can calculate gradient for itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scalar(w=3,grad=1)\n",
      "Scalar(w=4,grad=-5)\n",
      "Scalar(w=5,grad=0)\n"
     ]
    }
   ],
   "source": [
    "class Scalar:\n",
    "    \n",
    "    def __init__(self, data, prev = () ) -> None:\n",
    "        self.data: float = data if data is not None else random.uniform(-1, 1)\n",
    "        self.grad: float = 0\n",
    "        self.prev: tuple[\"Scalar\"] = prev\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"Scalar(w={self.data},grad={self.grad})\"\n",
    "\n",
    "    def __add__(self, other: \"Scalar\") -> \"Scalar\":\n",
    "        if not isinstance(other, Scalar):\n",
    "            other = Scalar(other)\n",
    "\n",
    "        def _backward(prev: tuple[\"Scalar\", \"Scalar\"], d_out):\n",
    "            return d_out, d_out\n",
    "\n",
    "        out = Scalar(self.data + other.data, prev = (self, other))\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def __mul__(self, other: \"Scalar\") -> \"Scalar\":\n",
    "        if not isinstance(other, Scalar):\n",
    "            other = Scalar(other)\n",
    "        \n",
    "        def _backward(prev: tuple[\"Scalar\", \"Scalar\"], d_out):\n",
    "            lval, rval = prev\n",
    "            return rval.data * d_out, lval.data * d_out \n",
    "\n",
    "        out = Scalar(self.data * other.data, prev = (self, other))\n",
    "        out._backward = _backward\n",
    "        \n",
    "        return out\n",
    "\n",
    "    def __pow__(self, power: int):\n",
    "        if isinstance(power, Scalar):\n",
    "            power = power.data\n",
    "\n",
    "        def _backward(prev, d_out):\n",
    "            val, = prev\n",
    "            return (power * (val.data ** (power - 1)) * d_out,) \n",
    "\n",
    "        out = Scalar(self.data ** power, prev = (self,))\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "        \n",
    "    def sigmoid(self) -> \"Scalar\":\n",
    "        sigmoid_fn = lambda x: 1 / (1 + math.exp(-x))  # noqa: E731\n",
    "\n",
    "        def _backward(prev: tuple[\"Scalar\"], d_out):\n",
    "            d_out = sigmoid_fn(prev[0]) * (1 - sigmoid_fn(prev[0])) * d_out \n",
    "            prev[0].grad += d_out\n",
    "            return (d_out,)\n",
    "\n",
    "        out = Scalar(sigmoid_fn(self.data), (self,))\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "\n",
    "\n",
    "    \"\"\" Handle other use cases using base operations. \"\"\"\n",
    "\n",
    "    def __neg__(self) -> \"Scalar\":  # -self\n",
    "        return self * -1\n",
    "\n",
    "    def __radd__(self, other: \"Scalar\") -> \"Scalar\":  # other + self\n",
    "        return self + other\n",
    "\n",
    "    def __sub__(self, other: \"Scalar\") -> \"Scalar\":  # self - other\n",
    "        return self + (-other)\n",
    "\n",
    "    def __rsub__(self, other: \"Scalar\") -> \"Scalar\":  # other - self\n",
    "        return other + (-self)\n",
    "\n",
    "    def __rmul__(self, other: \"Scalar\") -> \"Scalar\":  # other * self\n",
    "        return self * other\n",
    "\n",
    "    def __truediv__(self, other: \"Scalar\") -> \"Scalar\":  # self / other\n",
    "        return self * other**-1\n",
    "\n",
    "    def __rtruediv__(self, other: \"Scalar\") -> \"Scalar\":  # other / self\n",
    "        return other * self**-1\n",
    "\n",
    "    \"\"\" Backpropagation \"\"\"\n",
    "\n",
    "    def is_leaf(self):\n",
    "        return len(self.prev) == 0\n",
    "\n",
    "    def _backward():\n",
    "        \"\"\" \n",
    "        Function attached to every arithmetic operation to calculate the derivative in the chain \n",
    "\n",
    "        Backward function keeps reference to [self], [other] and [out] Scalar value, and is directly tied to the arithmetic primitive.\n",
    "        \"\"\"\n",
    "        ...\n",
    " \n",
    "    @staticmethod\n",
    "    def topological_sort(v) -> list[\"Scalar\"]:\n",
    "        visited = set()\n",
    "        topo = [v]\n",
    "        qu = [v]\n",
    "        while qu:\n",
    "            node = qu.pop(0)\n",
    "            if node in visited:\n",
    "                continue\n",
    "            visited.add(node)\n",
    "\n",
    "            for child in v.prev:\n",
    "                if not isinstance(child, Scalar) or child.is_leaf():\n",
    "                    continue\n",
    "                qu.append(child)\n",
    "                topo.append(child)\n",
    "        return topo                    \n",
    "\n",
    "    def backward(self):\n",
    "        deriv = 1\n",
    "        topo = self.topological_sort(self)\n",
    "        for node in topo:\n",
    "            for scalar, deriv in zip(node.prev, node._backward(node.prev, deriv)):\n",
    "                if scalar.is_leaf():\n",
    "                    scalar.grad += deriv\n",
    "                else:\n",
    "                    scalar.grad = deriv\n",
    "\n",
    "a = Scalar(3)\n",
    "b = Scalar(4)        \n",
    "c = Scalar(5)        \n",
    "d = a - b\n",
    "# e = d / c\n",
    "\n",
    "d.backward()\n",
    "\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "# print(e)\n",
    "\n",
    "# mlp = NeuralNetwork(1, [\n",
    "#     StateVector(1, 10),\n",
    "#     StateVector(10, 10),\n",
    "#     StateVector(10, 1)\n",
    "# ])\n",
    "# mlp([1])\n",
    "\n",
    "# EPOCHS = 10\n",
    "# for epoch in range(EPOCHS):\n",
    "#     preds = [mlp([i])[0] for i in x]\n",
    "#     error = [(y_true - y_pred) ** 2 for y_true, y_pred in zip(y, preds)]\n",
    "#     total_error = sum(error)\n",
    "#     total_error.backward() # accumulate gradients\n",
    "\n",
    "#     for p in mlp.parameters():\n",
    "#         p.data += -0.1 * p.grad # update weights\n",
    "\n",
    "#     print(\"Total Error: \", total_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for a: tensor([3.]) tensor([1.])\n",
      "Gradient for b: tensor([4.]) tensor([-1.])\n",
      "Gradient for c: None\n"
     ]
    }
   ],
   "source": [
    "import torch  # Use torch directly for clarity\n",
    "\n",
    "# Set requires_grad=True at the time of tensor creation\n",
    "a = torch.tensor([3.0], requires_grad=True)\n",
    "b = torch.tensor([4.0], requires_grad=True)\n",
    "c = torch.tensor([5.0], requires_grad=True)\n",
    "\n",
    "# Perform operations\n",
    "d = a - b\n",
    "# e = d / c\n",
    "\n",
    "# Now, you can call backward on e, as it has been computed with tensors that have requires_grad=True\n",
    "d.backward()\n",
    "\n",
    "# Print gradients\n",
    "print(\"Gradient for a:\", a.data, a.grad)  # This will show the gradient of e with respect to a\n",
    "print(\"Gradient for b:\", b.data, b.grad)  # This will show the gradient of e with respect to b\n",
    "print(\"Gradient for c:\", c.grad)  # This will show the gradient of e with respect to c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
